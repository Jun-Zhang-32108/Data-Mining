# -*- coding: utf-8 -*-
# Author: Jun Zhang <jun.1.zhang@aalto.fi>, Zhiheng Qian 
# Date: Dec 3rd, 2019
"""GraphPartion.ipynb

Automatically generated by Colaboratory.

Original file (old version) is located at
    https://colab.research.google.com/drive/13GnsbliLVICp9f0YQcMmSpuHeYYy75a_
"""

import sys
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.sparse import csgraph
import scipy.sparse.linalg as linalg
from scipy import sparse
from sklearn.cluster import KMeans, AgglomerativeClustering, MiniBatchKMeans
from sklearn.preprocessing import normalize
import networkx as nx
import argparse
import datetime
start = datetime.datetime.now()

parser = argparse.ArgumentParser()
parser.add_argument("dataset", type=str, help="Input the dataset name to be computed")
parser.add_argument("--save", action='store_true', help="Save the computed eigenvectors")

args = parser.parse_args()

# bookkeeping
stat= np.zeros((6,5))
stat = pd.DataFrame(stat, columns=['Name','Objective','Class Number','Mean','STD'])


# Not used

# def selfLoop_identifier(x,y):
#   if x==y:
#     print('SelfLoop: {} - {}'.format(x,y))
# data_df.apply(lambda x: selfLoop_identifier(x[0], x[1]), axis= 1)

# Read the input parameter
graph_name = args.dataset
path = 'graphs_processed/' + graph_name
# path       = graph_name
test_data1 = open(path).readline()
first_line = test_data1.strip('\n').split(' ')
graphID    = first_line[1]
vertices_n = int(first_line[2])
edges_n    = int(first_line[3])
k          = int(first_line[4])
print("GraphID: {}    vertices_n: {}   edges_n: {}    k: {}".format(graphID,vertices_n, edges_n, k))
stat.iloc[0,:] = [graphID, 0, vertices_n, edges_n, k]

# Construct the sparse matrix for the graph
graph_matrix = sparse.lil_matrix((vertices_n, vertices_n))
def adjacent_matrix_construction(x,y):
  if x!=y:
    graph_matrix[x, y] = 1
    graph_matrix[y, x] = 1
edges_df = pd.read_csv(path, sep = ' ', skiprows=1, header=None, names=['Vertex1', 'Vertex2'])
edges_df.apply(lambda x: adjacent_matrix_construction(x[0],x[1]), axis=1)

# Construct the Laplacian matrix
Laplacian_graph = csgraph.laplacian(graph_matrix, normed= False)

# Visualization
# graph_nx = nx.from_pandas_edgelist(edges_df, 'Vertex1', 'Vertex2')
# nx.draw(graph_nx)

vals, vecs = linalg.eigs(Laplacian_graph, k=k, sigma = 0)
vecs = np.real(vecs)
# vecs = normalize(vecs, norm='l1', axis=1)
K_start = datetime.datetime.now()
kmeans = KMeans(n_clusters=k).fit(vecs)
K_end = datetime.datetime.now()
print('Kmeans uses time: {}'.format(K_end-K_start))
classes, class_numbers = np.unique(kmeans.labels_, return_counts=True)
print('Class Numbers KMeans: {}'.format(class_numbers))

# np.trace(vecs.T.dot(Laplacian_graph).dot(vecs))

# Objective function
def objective(edges, labels, k, class_numbers):
    cut_edges = {}
    for i in range(k):
      cut_edges[i]= 0
    def accumulate(vertex1, vertex2):
      if labels[vertex1] != labels[vertex2]:
        cut_edges[labels[vertex1]] += 1
        cut_edges[labels[vertex2]] += 1
    edges.apply(lambda x: accumulate(x[0],x[1]), axis = 1)
    objective = 0
    for j in cut_edges:
      objective += cut_edges[j]/class_numbers[j]
    return objective
objective_value = objective(edges_df, kmeans.labels_, k, class_numbers)
objective_min   = objective_value
print('Objective Value KMeans: {}'.format(objective_value))

# Output the result
output = open("result/"+graphID + ".output","w+")
output.write('# '+ graphID + " " + str(vertices_n) + " " + str(edges_n) + " " + str(k) + "\n")
for i in range(vertices_n):
     output.write(str(i) +" " +str(kmeans.labels_[i])+"\n")
output.close()
norm_class_numbers = np.array(class_numbers)/vertices_n
mean_dist = np.mean(norm_class_numbers)
std_d = np.std(norm_class_numbers)
stat.iloc[1,:] = ['Kmeans', objective_value, str(class_numbers), mean_dist, std_d]
print('Mean: {}'.format(mean_dist))
print()

#-------------------------------------------------------
# Try out different approaches
#-------------------------------------------------------
# Find the maximum feature of the embeddings of each vertex and output the index as the cluster ID
labels_new = []
class_numbers_new = []
for i in vecs:
  labels_new.append(np.argmax(i))
for i in range(k):
  class_numbers_new.append(labels_new.count(i))
print('Class Number: {}'.format(class_numbers_new))
try:
  objective_find_max = objective(edges_df, labels_new, k, class_numbers_new)
except ZeroDivisionError:
  objective_find_max = 0
  print('At lease one class does not have any vertices')
print('Objective findMax: {}'.format(objective_find_max))
if objective_find_max < objective_min:
  objective_min = objective_find_max
  print('Using find_max method yields a better result!')
output = open("result/"+graphID + "_findMax.output","w+")
output.write('# '+ graphID + " " + str(vertices_n) + " " + str(edges_n) + " " + str(k) + "\n")
for i in range(vertices_n):
  output.write(str(i) +" " +str(labels_new[i])+"\n")
norm_class_numbers = np.array(class_numbers_new)/vertices_n
mean_dist = np.mean(norm_class_numbers)
std_d = np.std(norm_class_numbers)
print('STD: {}'.format(std_d))
stat.iloc[2,:] = ['findMax', objective_find_max, str(class_numbers_new), mean_dist, std_d]
output.close()
print()

# Use MinBatchKmeans for clustering instead of kmeans
MBK_start = datetime.datetime.now()
clustering_MBKmeans = MiniBatchKMeans(n_clusters=k, n_init=10, tol=1e-4).fit(vecs)
MBK_end = datetime.datetime.now()
print ('MiniBatchKmeans uses time: {}'.format(MBK_end-MBK_start))
classes, class_numbers_MBK = np.unique(clustering_MBKmeans.labels_, return_counts=True)
objective_MBK = objective(edges_df, clustering_MBKmeans.labels_, k, class_numbers_MBK)
print('Class Number MiniBatchKmeans: {}'.format(class_numbers_MBK))
print('Objective MBK: {}'.format(objective_MBK))
if objective_MBK < objective_min:
  objective_min = objective_MBK
  print('Using MiniBatchKmeans method yields a better result!')
output = open("result/"+graphID + "_MBK.output","w+")
output.write('# '+ graphID + " " + str(vertices_n) + " " + str(edges_n) + " " + str(k) + "\n")
for i in range(vertices_n):
  output.write(str(i) +" " +str(clustering_MBKmeans.labels_[i])+"\n")
output.close()
norm_class_numbers = np.array(class_numbers_MBK)/vertices_n
mean_dist = np.mean(norm_class_numbers)
std_d = np.std(norm_class_numbers)
print('STD: {}'.format(std_d))
stat.iloc[3,:] = ['MiniBatchKmeans', objective_MBK, str(class_numbers_MBK), mean_dist, std_d]
print()

# Use AgglomerativeClustering for clustering instead of kmeans
# This may led to memory error.
try:
  clustering = AgglomerativeClustering(n_clusters=k).fit(vecs)
  classes, class_numbers_agg = np.unique(clustering.labels_, return_counts=True)
  objective_agg = objective(edges_df, clustering.labels_, k, class_numbers_agg)
  print('Class Number Agg: {}'.format(class_numbers_agg))
  print('Objective Agg: {}'.format(objective_agg))
  if objective_agg < objective_min:
    objective_min = objective_agg
    print('Using AgglomerativeClustering method yields a better result!')
  output = open("result/"+graphID + "_agg.output","w+")
  output.write('# '+ graphID + " " + str(vertices_n) + " " + str(edges_n) + " " + str(k) + "\n")
  for i in range(vertices_n):
    output.write(str(i) +" " +str(clustering.labels_[i])+"\n")
  norm_class_numbers = np.array(class_numbers_agg)/vertices_n
  mean_dist = np.mean(norm_class_numbers)
  std_d = np.std(norm_class_numbers)
  print('STD: {}'.format(std_d))
  stat.iloc[4,:] = ['Agg', objective_agg, str(class_numbers_agg), mean_dist, std_d]
  output.close()
  print()
except MemoryError:
  print('Not enough memory!')

# Call the SpectralClustering from sklearn and compare
# We include this part just want to see if our implementation of spectral clustering is better or not 
# This may lead to memory error
try: 
  from sklearn.cluster import SpectralClustering
  clustering_spectral = SpectralClustering(n_clusters=k,
          assign_labels="kmeans",
          eigen_solver = 'arpack',
          gamma = 0,
          affinity = 'precomputed').fit(graph_matrix)
  classes, class_numbers = np.unique(clustering_spectral.labels_, return_counts=True)
  print('Class numbers Spectral: {}'.format(class_numbers))
  objective_spectral = objective(edges_df, clustering_spectral.labels_, k, class_numbers)
  print('Objective Spectral: {}'.format(objective_spectral))
  if objective_spectral < objective_min:
    print('Using SpectralClustering from sklearn yields a better result!')
    objective_min = objective_spectral
  output = open("result/"+graphID + "_Spectral.output","w+")
  output.write('# '+ graphID + " " + str(vertices_n) + " " + str(edges_n) + " " + str(k) + "\n")
  for i in range(vertices_n):
    output.write(str(i) +" " +str(clustering_spectral.labels_[i])+"\n")
  norm_class_numbers = np.array(class_numbers)/vertices_n
  mean_dist = np.mean(norm_class_numbers)
  std_d = np.std(norm_class_numbers)
  print('STD: {}'.format(std_d))
  stat.iloc[5,:] = ['Spectral', objective_spectral, str(class_numbers), mean_dist, std_d]
  output.close()
  print()
except MemoryError:
  print('Memory is not enough!')

stat.to_csv('stat/'+graphID+'_stat.csv')
if args.save:
  vecs_df = pd.DataFrame(vecs)
  vecs_df.to_csv('vecs/'+graphID + '_vecs.csv')

end = datetime.datetime.now()
print ('Use time: {}'.format(end-start))
print()
print()
